---
title: "Twenty-Five Things You Didn't Know You Could Do with R"
format:
  rfortherestofus-slides-revealjs:
    menu: false
    progress: false
    slide-number: true
    show-slide-number: print
    center: true
    incremental: true
    auto-animate: true
    slide-level: 4
    output-location: slide
    spotlight:
      presentingCursor: default
knitr:
  opts_chunk:
    dev: "png"
    dpi: 300
execute: 
  message: false
  warning: false
  cache: false
  echo: true
title-slide-attributes:
  data-background-image: assets/rru-hex-bg-gradient-dark.svg
  data-background-size: cover
editor_options: 
  chunk_output_type: console
revealjs-plugins:
  - spotlight
---



```{r}
#| echo: false
options(tigris_use_cache = TRUE)
library(tidyverse)
```

# Twenty-Five Things You Didn't Know You Could Do with R {.inverse .center}

::: {.notes}
Hi, I'm David Keyes and I run R for the Rest of Us. I'm excited to be here today and to talk with you about doing things in R you didn't know you could do. Twenty-five things to be precise. 

I find it ironic in many ways that I am up here talking to you about unique ways to use R. I say that because for a long time I didn't feel like a "real" R user. You see, I don't come from a typical R background. I'm a qualitative researcher with a PhD in anthropology. I don't have advanced training in statistics. When I started using R I felt like I wasn't a real R user because the most complicated stats I calculated then, and still calculate now, were descriptive stats. 

But eventually I realized that R isn't just about stats. Or, more precisely, R can do more than just complicated statistical techniques. Eventually, I learned to use R for things like data visualization, reproducible reporting, making maps, and much more. R became my Swiss Army knife, enabling me to do anything I needed to with data.

And the more I started talking with others about how I used R, they were, to my surprise, quite interested. Eventually, I came to peace with how I used R. I didn't need to do complicated statistics to be a real R user. And, in fact, even among people who do use R for complicated stats, R's capabilities as a more general purpose tool are extremely appealing. My goal today is to show you a few things that you can do with R that you may never have considered.  

Now, before I get started, just one thing: not everything you will hear me talk about today is going to be new to you. It's impossible to choose twenty-five things that no one in a group of this size will be familiar with. But my hope is that you come away with at least a few new ideas for ways you can use R that you never previously considered. 
:::

---

::: {.r-fit-text}
https://rfortherestofus.com/cascadia2025
:::

# Access Data Automagically {.inverse background-image="assets/automagically.jpg"}

::: {.notes}
Before you do any work in R, you need data. Let's begin by talking about ways that you can access data directly from R. 
:::

## Pull in Data Directly from Google Sheets {.inverse}

:::{.big-number}
1
:::

::: {.notes}
As a social scientist, I conduct a lot of surveys. Now that I use R, one of my favorite ways to conduct surveys is with Google Forms. 

**Resources**

- Book chapter
:::

---

![](assets/google-form-v2.png){.r-stretch fig-align="center"}


---

![](assets/google-sheet-v2.png){.r-stretch fig-align="center"}

::: {.notes}
Using Google Forms allows me to put survey responses directly into Google Sheets. 
:::

---


::: {.r-fit-text}
```{r}
#| eval: false
library(googlesheets4)

survey_data <-
  read_sheet(YOURSHEETURLHERE)
```
:::

::: {.notes}
And having data in Google Sheets allows me to use the {googlesheets4} package to access that data directly from R. 
:::

---

### Spring 2024

![](assets/survey-spring-2024.png){.r-stretch fig-align="center"}

### Fall 2024

![](assets/survey-fall-2024.png){.r-stretch fig-align="center"}

::: {.notes}
This means that every time a new response comes in, it just takes you rerunning your code in order to create new analysis, data viz, etc. 

**Resources**

- Book chapter
:::


## Pull in Data Directly from Qualtrics {.inverse}


:::{.big-number}
2
:::

---

::: {.r-fit-text}
```{r}
#| eval: false
library(qualtRics)

survey_data <-
  fetch_survey(surveyID = "YOURSURVEYIDHERE")
```
:::

::: {.notes}
Another common tool for those collecting surveys is Qualtrics. And, fortunately for you, if you use Qualtrics, there is a package to bring in data directly from it. With the `fetch_survey()` function, you can bring in data from a Qualtrics survey, ensuring you are always working with the most up-to-date data. 
:::

## Pull in Data Directly from the Census Bureau {.inverse}

:::{.big-number}
3
:::


::: {.notes}
A third way that I like to connect directly to my data source is with the {tidycensus} package. I work with a lot of data from the Census Bureau. 
:::

---

![](assets/largest-communities-oregon.png)

---

![](/assets/census-bureau-website.png){.r-stretch fig-align="center"}

::: {.notes}
Before I used R, I would spend hours on the Census Bureau website, finding the data I needed, downloading it, and then working with it in Excel. 
:::

---

::: {.r-fit-text}
```{r}
#| eval: true
library(tidycensus)

get_acs(
  state = "OR",
  geography = "place",
  geometry = TRUE,
  variables = "B01003_001"
)
```
:::

::: {.notes}
But with the {tidycensus} package, I can connect directly to the Census Bureau, pulling in data on command. 

This approach has proven particularly helpful in my work on the annual Oregon by the Numbers report, which relies heavily on data from the American Community Survey. 
:::

## Work with APIs to Access Data {.inverse}

:::{.big-number}
4
:::


::: {.notes}
Under the hood, the {googlesheets4}, {qualtRics}, and {tidycensus} packages connect to data sources through APIs. Fortunately for us, they hide the often complicated work of accessing data through APIs. Unfortunately for us, there are times when we need to access data available through APIs, but without a wrapper package to simplify the process. In this case, the {httr2} package enables us to connect directly with APIs. 
:::

---

![](/assets/dashboard.png){.r-stretch fig-align="center"}

::: {.notes}
For example, I have an internal dashboard I use to pull in data from multiple sources. 
:::

---

```{r}
#| eval: false
library(httr2)

fathom_api_key <- Sys.getenv("FATHOM_API_KEY")

request("https://api.usefathom.com/v1/aggregations") |>
  req_url_query(
    entity = "pageview",
    aggregates = "visits,uniques,pageviews",
    sort_by = "visits:desc"
  ) |>
  req_headers(
    Authorization = str_glue("Bearer {fathom_api_key}")
  ) |>
  req_perform()
```


::: {.notes}
Since few of these tools have dedicated R packages, I write code to connect to them directly. 
:::

---

```{r}
#| echo: false

read_rds(here::here("data/df_fathom.rds")) |>
  select(-page_type)
```


## Scrape Data {.inverse}

:::{.big-number}
5
:::


::: {.notes}
There are other times when we want to access data and is there is no package to access it, nor is there an API to enable us to connect to the data source. In this case, we often need to scrape data from webpages. The {rvest} package is your friend in this case. 
:::

---

![](/assets/world-cup-finals.png){.r-stretch fig-align="center"}

---

::: {.r-fit-text}
```{r}
library(rvest)
library(tidyverse)

read_html("https://en.wikipedia.org/wiki/List_of_FIFA_World_Cup_finals") |>
  html_elements("table") |>
  pluck(4) |>
  html_table() |>
  select(-Ref.)
```
:::


# Efficiently Make Beautiful Data Viz {.inverse background-image="assets/graph.jpg"}

## Make Your Own Theme {.inverse}

:::{.big-number}
6
:::

::: {.notes}
If you make plots in ggplot (and if you're here, I'm guessing you do), keeping them consistent and on brand can be challenging. Fortunately, this is where themes come in. If you've never tried to make your own ggplot theme, you should! It's surprisingly simple and with a few lines of code you can ensure that all of your plots are on brand.

**Resources**

- Jadey blog post
- Book chapter
:::



---


```{r}
#| echo: false
library(palmerpenguins)
library(scales)

penguins_bar_chart <-
  penguins |>
  drop_na(island, bill_length_mm) |>
  group_by(island) |>
  summarize(avg_bill_length = mean(bill_length_mm)) |>
  ungroup() |>
  mutate(avg_bill_length_formatted = number(avg_bill_length, accuracy = 0.1)) |>
  ggplot(aes(
    x = island,
    y = avg_bill_length
  )) +
  geom_col() +
  # geom_text(
  #   aes(label = avg_bill_length_formatted),
  #   vjust = 1.5,
  #   color = "white"
  # ) +
  labs(
    title = "Average bill length of penguins by island",
    subtitle = "Data shown in millimeters",
    caption = "Source: {palmerpenguins} package"
  )
```

```{r}
#| echo: false
penguins_bar_chart
```


---

```{r}
#| echo: false

theme_dk <- function(base_family = "Inter Tight", base_size = 14) {
  theme_dk <-
    ggplot2::theme_minimal(
      base_size = base_size,
      base_family = base_family
    ) +
    ggplot2::theme(
      panel.grid.minor = ggplot2::element_blank(),
      panel.grid.major = ggplot2::element_line(
        color = "grey90",
        linewidth = 0.5,
        linetype = "dashed"
      ),
      axis.ticks = ggplot2::element_blank(),
      axis.text = ggplot2::element_text(
        color = "grey50",
        size = ggplot2::rel(0.8)
      ),
      axis.title = ggplot2::element_blank(),
      plot.title.position = "plot",
      plot.title = ggplot2::element_text(
        face = "bold",
        size = ggplot2::rel(1.5)
      ),
      plot.subtitle = ggplot2::element_text(
        color = "grey40",
        size = ggplot2::rel(1.1)
      ),
      plot.caption = ggplot2::element_text(
        color = "grey50",
        margin = ggplot2::margin(t = 20)
      ),
      plot.margin = ggplot2::margin(10, 10, 10, 10),
      strip.text = ggplot2::element_text(
        color = "grey40",
        size = ggplot2::rel(0.9)
      ),
      panel.spacing = ggplot2::unit(2, "lines")
    )

  theme_dk
}
```


:::{.r-fit-text}

```{r}
#| eval: false
library(tidyverse)

theme_dk <- function(base_family = "Inter Tight", base_size = 14) {
  theme_minimal(base_size = base_size, base_family = base_family) +
    theme(
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(
        color = "grey90",
        linewidth = 0.5,
        linetype = "dashed"
      ),
      axis.text = element_text(
        color = "grey50"
      ),
      ETC
    )
}
```

:::

---

::: {.r-fit-text}
```{r}
penguins_bar_chart +
  theme_dk()
```
:::



---

## Use Your Theme Everywhere {.inverse}

:::{.big-number}
7
:::

---

````{markdown}
#| eval: false
```
title: "Penguins Report"
```

```{r}
theme_dk <- function(base_family = "Inter Tight", base_size = 14) {}
```

```{r}
theme_set(theme_dk())
```

```{r}
penguins_bar_chart
```
````

---

![](/assets/penguins_bar_chart-with-theme 1.png){.r-stretch fig-align="center"}

## Make Your Text Consistent with Your Theme {.inverse}

:::{.big-number}
8
:::


::: {.notes}
Creating a theme is a great way to handle the look and feel of things like titles, axis text, grid lines, etc. What themes do not change is text added through geoms. 
:::




---

::: {.r-fit-text}
```{r}
#| output-location: slide
penguins_bar_chart +
  theme_dk(base_family = "IBM Plex Mono", base_size = 12) +
  geom_text(
    aes(label = avg_bill_length_formatted),
    vjust = 1.5,
    color = "white",
    size = 4
  )
```
:::

::: {.notes}
So, let's say you want to use `geom_text()` to add labels to your plot. See here how I've added a layer to my plot to add labels that show the average bill length. You'll also see that I've changed the font in my theme to be IBM Plex Mono just to make it more obvious. 

When I run my code I get a plot that uses IBM Plex Mono everywhere except where `geom_text()` added labels.
:::



---

::: {.r-fit-text}
```{r}
#| output-location: slide
penguins_bar_chart +
  theme_dk(base_family = "IBM Plex Mono", base_size = 12) +
  geom_text(
    aes(label = avg_bill_length_formatted),
    vjust = 1.5,
    color = "white",
    family = "IBM Plex Mono",
    size = 4
  )
```
:::

::: {.notes}
The way most people change this is by adding `family = "IBM Plex Mono"` within `geom_text()`. This is fine to do in one or two charts, but say you're making an entire report with dozens of charts. You don't want to have to add `family = "IBM Plex Mono"` dozens of times. The way around this is with the `update_geom_defaults()` function. This function lets you set defaults for various geoms. 
:::

---

::: {.r-fit-text}
```{r}
update_geom_defaults(
  geom = "text",
  aes(family = "IBM Plex Mono")
)
```
:::

::: {.notes}
Here, for example, you can set the default family for all geom_text() instances to be IBM Plex Mono. 
:::

---

````{markdown}
#| eval: false
```
title: "Penguins Report"
```

```{r}
theme_dk <- function()
```

```{r}
theme_set(theme_dk())

update_geom_defaults(geom = "text", aes(family = "IBM Plex Mono"))
```

```{r}
penguins_bar_chart +
  geom_text(
    aes(label = avg_bill_length_formatted),
    vjust = 1.5,
    color = "white",
    size = 4
  )
```
````

::: {.notes}
Just put this code at the top of your R script or Quarto document and all of your charts will use IBM Plex Mono everywhere. 
:::

---

```{r}
#| echo: false
theme_set(theme_dk(base_family = "IBM Plex Mono", base_size = 12))

update_geom_defaults(geom = "text", aes(family = "IBM Plex Mono"))

penguins_bar_chart +
  geom_text(
    aes(label = avg_bill_length_formatted),
    vjust = 1.5,
    color = "white",
    size = 4
  )
```



# Make Maps  {.inverse background-image="assets/maps.jpg"}

## Make Maps with ggplot {.inverse}

:::{.big-number}
9
:::

::: {.notes}
R is renowned for its graph-making capabilities. Did you know that you can use ggplot, that same package you use to make graphs, to make maps? There is a special geom (geom_sf()) that allows you to make maps. And everything you have learned about ggplot applies to maps too: color and fill scales, themes, and more.

**Resources**

- Book chapter
- Course
:::

---

::: {.r-fit-text}
```{r}
library(tidycensus)

median_income_by_county <-
  get_acs(
    geography = "county",
    variables = c(median_income = "B19013_001"),
    geometry = TRUE
  )
```
:::

---

::: {.r-fit-text}
```{r}
#| output-location: fragment
median_income_by_county
```
:::

---

```{r}
#| output-location: slide
library(tidyverse)
library(tigris)
library(scales)

median_income_by_county |>
  shift_geometry() |>
  ggplot(aes(fill = estimate)) +
  geom_sf(linewidth = 0) +
  scale_fill_viridis_c(
    option = "B",
    labels = dollar_format(),
    name = NULL
  ) +
  theme_void()
```


## Do Geospatial Analysis {.inverse}

:::{.big-number}
10
:::

::: {.notes}
It's not just mapping that you can do in R. If you need to do geospatial analysis in R, that's very possible! While many people think of tools like ArcGIS for geospatial analysis, R is a fully-fledged GIS tool. A client we work with recently asked me to do an analysis of SNAP-Ed program sites within 5 miles of grocery stores. With just a few lines of code, I was able to tell her the sites that met this criteria. This is just one example of how you can use R for geospatial analysis. 

**Reference**
https://github.com/MichiganFitnessFoundation/mff-r-training/issues/74
:::

---

```{r}
#| eval: false
#| echo: false

# Data from https://rlisdiscovery.oregonmetro.gov/datasets/da2229f19d854845ae6e164d4924fe7a_0/explore?location=45.547982,-122.660240,12.42

metro_libraries <- read_sf("data/libraries.geojson") |>
  clean_names()

metro_libraries |>
  filter(city == "Portland") |>
  select(library = name) |>
  write_sf("data/portland_libraries.geojson")
```

```{r}
#| echo: false

library(sf)

portland_center_coords <-
  read_sf("data/portland_boundaries.geojson") |>
  st_centroid() |>
  st_coordinates() |>
  as_tibble() |>
  pivot_longer(cols = everything()) |>
  pull(value)
```


::: {.r-fit-text}
```{r}
library(sf)

portland_libraries <- read_sf("data/portland_libraries.geojson")
```
:::

. . .

```{r}
#| echo: false
portland_libraries
```


---

```{r}
#| echo: false
library(mapgl)

maplibre(bounds = portland_libraries) |>
  add_circle_layer(
    source = portland_libraries,
    circle_color = "#7570b3",
    tooltip = "library",
    id = "portland_libraries"
  )
```


---

```{r}
portland_libraries_one_mile_buffer <-
  portland_libraries |>
  st_buffer(1 * 1609.34)
```

. . .

```{r}
#| echo: false
portland_libraries_one_mile_buffer
```


---

```{r}
#| echo: false
maplibre(bounds = portland_libraries_one_mile_buffer) |>
  add_fill_layer(
    source = portland_libraries_one_mile_buffer,
    fill_color = "#7570b3",
    fill_opacity = 0.5,
    tooltip = "library",
    id = "portland_libraries"
  )
```

---

```{r}
#| eval: false
#| echo: false
# Data from https://nces.ed.gov/ccd/address.asp

read_csv("data/sc091aow.csv") |>
  filter(mstate09 == "OR") |>
  filter(mcity09 == "PORTLAND") |>
  filter(str_detect(schnam09, "ELEMENTARY")) |>
  select(schnam09:mzip09) |>
  set_names("school", "street_address", "city", "state", "zip_code") |>
  geocode(
    street = street_address,
    city = city,
    state = state,
    postalcode = zip_code,
    method = "census"
  ) |>
  st_as_sf(coords = c("long", "lat"), crs = 4326) |>
  select(school) |>
  mutate(school = str_to_title(school)) |>
  write_sf("data/pps_elementary_schools.geojson")
```


```{r}
pps_elementary_schools <-
  read_sf("data/pps_elementary_schools.geojson")
```

. . .

```{r}
#| echo: false
pps_elementary_schools
```

---

```{r}
#| echo: false
maplibre(bounds = pps_elementary_schools) |>
  add_circle_layer(
    source = pps_elementary_schools,
    circle_color = "black",
    tooltip = "library",
    id = "portland_libraries"
  )
```



---

```{r}
pps_elementary_schools |>
  st_join(portland_libraries_one_mile_buffer)
```

---


```{r}
pps_elementary_schools_near_libraries <-
  pps_elementary_schools |>
  st_join(portland_libraries_one_mile_buffer) |>
  mutate(has_nearby_library = case_when(
    is.na(library) ~ "Not within one mile of library",
    .default = "Within one mile of library"
  )) |>
  select(school, has_nearby_library)
```

. . .

```{r}
#| echo: false
pps_elementary_schools_near_libraries
```


---

```{r}
#| echo: false

# TODO: Center map

maplibre() |>
  add_fill_layer(
    source = portland_libraries_one_mile_buffer,
    fill_color = "#7570b3",
    fill_opacity = 0.5,
    tooltip = "library",
    id = "portland_libraries"
  ) |>
  add_circle_layer(
    source = pps_elementary_schools_near_libraries,
    circle_color = match_expr(
      "has_nearby_library",
      values = c(
        "Within one mile of library",
        "Not within one mile of library"
      ),
      stops = c(
        "#1b9e77",
        "#d95f02"
      )
    ),
    tooltip = "school",
    id = "schools"
  ) |>
  add_categorical_legend(
    values = c(
      "Within one mile of library",
      "Not within one mile of library"
    ),
    legend_title = NULL,
    colors = c("#1b9e77", "#d95f02"),
    circular_patches = TRUE
  )
```

## Make Interactive Maps {.inverse}

:::{.big-number}
11
:::

::: {.notes}
If you saw the interactive maps that I just showed and are wondering how I made, here's how. First, let me just point out that you can make interactive maps with R. There are many packages to do so, the most popular of which is {leaflet}. However, the one that I'm using, and which I'm a big fan of, is called {mapgl}. Using {mapgl}, I can make maps that I can embed in slides or, indeed, any HTML-based output. 
:::

---

```{r}
library(mapgl)

maplibre(bounds = pps_elementary_schools_near_libraries)
```

---

```{r}
maplibre(bounds = pps_elementary_schools_near_libraries) |>
  add_fill_layer(
    source = portland_libraries_one_mile_buffer,
    fill_color = "#7570b3",
    fill_opacity = 0.5,
    tooltip = "library",
    id = "portland_libraries"
  )
```

---

```{r}
maplibre(bounds = pps_elementary_schools_near_libraries) |>
  add_circle_layer(
    source = pps_elementary_schools_near_libraries,
    circle_color = match_expr(
      "has_nearby_library",
      values = c(
        "Within one mile of library",
        "Not within one mile of library"
      ),
      stops = c(
        "#1b9e77",
        "#d95f02"
      )
    ),
    tooltip = "school",
    id = "schools"
  )
```

---

```{r}
#| eval: false
maplibre(bounds = pps_elementary_schools_near_libraries) |>
  add_categorical_legend(
    values = c(
      "Within one mile of library",
      "Not within one mile of library"
    ),
    legend_title = NULL,
    colors = c(
      "#1b9e77",
      "#d95f02"
    ),
    circular_patches = TRUE
  )
```

---

```{r}
#| echo: false
maplibre(bounds = pps_elementary_schools_near_libraries) |>
  add_fill_layer(
    source = portland_libraries_one_mile_buffer,
    fill_color = "#7570b3",
    fill_opacity = 0.5,
    tooltip = "library",
    id = "portland_libraries"
  ) |>
  add_circle_layer(
    source = pps_elementary_schools_near_libraries,
    circle_color = match_expr(
      "has_nearby_library",
      values = c(
        "Within one mile of library",
        "Not within one mile of library"
      ),
      stops = c(
        "#1b9e77",
        "#d95f02"
      )
    ),
    tooltip = "school",
    id = "schools"
  ) |>
  add_categorical_legend(
    values = c(
      "Within one mile of library",
      "Not within one mile of library"
    ),
    legend_title = NULL,
    colors = c(
      "#1b9e77",
      "#d95f02"
    ),
    circular_patches = TRUE
  )
```





# Report in New Ways with Quarto  {.inverse background-image="assets/report.jpg"}

::: {.notes}
Whatever else you do in R, you need to report your results. As a tool designed for reproducible reporting, R is, of course, incredibly well designed for this purpose. Here are some ways you can improve your reporting in R.
:::

## Make Many Different Outputs with Quarto {.inverse}

:::{.big-number}
12
:::

::: {.notes}
When I teach people to use Quarto, I always start with simple outputs: single HTML files, PDFs, and Word documents. But Quarto can go beyond single documents. You can build a full website with Quarto, slides, and much more. 
:::


---

```{yaml}
---
title: "Median Income Report"
format: html
---
```

. . .

```{=html}
<iframe width="100%" height="500" src="examples/report.html"></iframe>
```


---

```{yaml}
---
title: "Median Income Presentation"
format: revealjs
---
```

. . .

```{=html}
<iframe width="100%" height="500" src="examples/slides.html"></iframe>
```

---

`index.qmd`

```{yaml}
---
title: "Median Income"
---
```

. . .

`about.qmd`

```{yaml}
---
title: "About"
---
```

. . .

`_quarto.yml`

```{yaml}
project:
  type: website

website:
  title: "Median Income Website"
  navbar:
    left:
      - index.qmd
      - about.qmd
  
format: html
```

---

```{=html}
<iframe width="100%" height="800" src="examples/website/_site/index.html"></iframe>
```

## Keep Your Quarto Outputs on Brand {.inverse}

:::{.big-number}
13
:::

::: {.notes}
A recent addition to the Quarto landscape is brand.yml. This framework allows you to add a single file, `_brand.yml`, to your project which lets you specify things like fonts, colors, logos, and more. Keeping your Quarto documents on brand has never been easier!

**Resources**
- brand.yml website
- Podcast with Garrick
:::

---

```{yaml}
meta:
  name: R for the Rest of Us
  link: https://rfortherestofus.com

color:
  palette:
    dark-blue: "#404e6b"
    blue: "#6cabdd"
  foreground: dark-blue
  primary: blue

typography:
  fonts:
    - family: Inter
      source: google
    - family: IBM Plex Mono
      source: google
  base: Inter
  headings: Inter
  monospace: IBM Plex Mono
```


---

```{=html}
<iframe width="100%" height="500" src="examples/brandyml/report.html"></iframe>
```

---

```{=html}
<iframe width="100%" height="500" src="examples/brandyml/slides.html"></iframe>
```

---

```{=html}
<iframe width="100%" height="800" src="examples/brandyml/website/_site/index.html"></iframe>
```

## Publish Your Quarto Documents Online {.inverse}

:::{.big-number}
14
:::

::: {.notes}
Creating reports in Quarto is just the first step. You also need to share them. If you render to some type of HTML output (this can be HTML files, websites, dashboards, slides, and more), you can publish them online. My favorite tool to do this is Netlify. Connect your GitHub repo to Netlify and every time you push updates they will show up online. 
:::

---

![](assets/netlify-connect-github.png)

---

![](assets/netlify-deploy.png)


---

::: {.r-fit-text}
https://cascadia2025.rfortherestofus.com
:::

## Make PDFs with Typst {.inverse}

:::{.big-number}
15
:::

::: {.notes}
Most people, when they think about making PDFs in Quarto, immediately think Latex. If this is enough to put you off from making PDFs in R, please know there is a new alternative. Known as typst, it is a modern reimagining of Latex. 

**Resources**
- My talk
:::

---



---

---

`report.qmd`

````{markdown}
#| eval: false
---
title: "Housing Data Profiles"

format: 
  typst:
    template-partials:
      - typst-show.typ
      - typst-template.typ

params:
  town: "Hartford"
---

# Introduction

Consequat occaecat mollit velit aliquip. etc ...
````

---

`typst-show.typ`

````{markdown}
#| eval: false
#show: psc-report.with(
  $if(title)$
    title: "$title$",
  $endif$
  $if(params.town)$
    town: "$params.town$",
  $endif$
)
````

---

`typst-template.typ`

````{markdown}
#| eval: false
#let psc-report(
  title: "title",
  town : "town",
  body,
) = {

 set text(
    font: "Open Sans",
    size: 12pt,
  )

 set page(
    "us-letter",
    margin: (left: 1in, 
             right: 1in, 
             top: 0.7in, 
             bottom: 1in),
    background: place(top, 
                      rect(fill: rgb("15397F"), 
                           width: 100%, 
                           height: 0.5in)),
    header: align(
      horizon,
      grid(
        columns: (80%, 20%),
        align(left, text(size: 20pt, fill: white, weight: "bold", title)),
        align(right, text(size: 12pt, fill: white, weight: "bold", town)),
      ),
    ),
    footer: align(
      grid(
        columns: (40%, 60%),
        align(horizon, text(fill: rgb("15397F"), 
                            size: 12pt, 
                            counter(page).display("1"))),
        align(right, image("assets/psclogo.svg", height: 300%)),
      )
    )
  )

  body
}

````

---

![](assets/typst-report.png){.shadow .rounded}

---

# Automate all the Things  {.inverse background-image="assets/automate.jpg"}

## Email Your Reports Directly from R {.inverse}

:::{.big-number}
16
:::

::: {.notes}
In 2020, at the start of the COVID pandemic, we were working with Prosper Portland, the small business development agency for the city of Portland. They had quickly started a grant program for businesses impacted by the pandemic. It was, like so much in those early days of COVID, thrown together quickly. They set up an application form and they wanted an easy way to see a summary of information about businesses seeking relief. We wrote code to pull data from a Google Sheet and create a summary report. And, best of all, we set it up to email the report directly to Prosper Portland staff using the {gmailr} package. 

**Resources**
- https://github.com/rfortherestofus/pp-covid-biz-relief/blob/master/render_gmail.R
- https://pkgs.rstudio.com/blastula/
:::

---

```{r}
#| eval: false

library(tidyverse)
library(quarto)

rendered_report <- str_glue("covid-business-relief-contact-log-{today()}.html")

quarto_render(
  input = "report.qmd",
  output_file = rendered_report
)
```

---

::: {.r-fit-text}
```{r}
#| eval: false

library(gmailr)

gm_auth_configure()
gm_auth(email = TRUE, cache = ".secret")

email_report <-
  gm_mime() |>
  gm_to("Joe Schmoe <joeschmoe@prosperportland.us>") |>
  gm_from("David Keyes <david@rfortherestofus.com>") |>
  gm_subject("COVID Business Relief Contact Log") |>
  gm_text_body("See attached") |>
  gm_attach_file(rendered_report)

gm_send_message(email_report)
```
:::



---

## Run Your Code Without Lifting a Finger {.inverse}

:::{.big-number}
17
:::

::: {.notes}
In 2020, at the start of the COVID pandemic, we were working with Prosper Portland, the small business development agency for the city of Portland. They had quickly started a grant program for businesses impacted by the pandemic. It was, like so much in those early days of COVID, thrown together quickly. They set up an application form and they wanted an easy way to see a summary of information about businesses seeking relief. We wrote code to pull data from a Google Sheet and create a summary report. And, best of all, we set it up to email the report directly to Prosper Portland staff using the {gmailr} package. 

**Resources**
- https://github.com/rfortherestofus/pp-covid-biz-relief/blob/master/render_gmail.R
- https://pkgs.rstudio.com/blastula/
:::

---


```{yaml}
#| eval: false
name: Render Report and Send It

on:
  schedule:
    - cron:  '00 14 * * 1-5'
jobs:
  build:
    runs-on: ubuntu-latest
    container: rocker/geospatial
    
    env:
      GMAILR_APP: ${{ secrets.GMAILR_APP }}
      GMAILR_EMAIL: ${{ secrets.GMAILR_EMAIL }}
```


---


```{yaml}
   steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Install dependencies
        run: |
          install.packages("remotes")
          remotes::install_cran("quarto")
          remotes::install_cran("gmailr")
          ETC
        shell: Rscript {0}
          
      - name: Render + Send
        run: |-
          Rscript render_gmail.R
```


## Use R to Work With Files Created in R {.inverse}

:::{.big-number}
18
:::

::: {.notes}
Speaking of automation, I often have to move files around. For example, when working on the annual Oregon by the Numbers Report, I make a ton of plots that I have to share with the graphic designer who lays out the report. I used to manually copy all of these files and upload them to Google Drive. But then I came across the {fs} and {zip} packages. I use {fs} to create a list of all the files I've created, which I then pass to the {zip} package in order to create a zip file. And, if I'm feeling extra fancy, I upload the zip file automatically to Google Drive using the {googledrive} package. With all of this, I just have to run my code and share a single link with the designer.

**Resources**
- 250 plots blog post
- https://albert-rapp.de/posts/36_fs_package/
:::

---

![](assets/county-pages.png)

---

![](assets/measure-pages.png)


---

::: {.r-fit-text}
```{r}
#| eval: false
library(fs)
library(zip)
library(tidyverse)

county_pages <- dir_ls("outputs/pages/county/")

measure_pages <- dir_ls("outputs/pages/measure/")

all_pages_zip <-
  zip(
    zipfile = str_glue("outputs/zip/{obtn_year}-obtn-files-{today()}.zip"),
    files = c(county_pages, measure_pages)
  )
```
:::

---

::: {.r-fit-text}
```{r}
#| eval: false

library(googledrive)

drive_upload(all_pages_zip)
```
:::


# Use AI to Write Better Code  {.inverse background-image="assets/ai-write-code.jpg"}

::: {.notes}
Let's finish off by talking about ways that you can use large language models when working with R. Now I'm not an AI hype boy here to tell you that this or that model will blow your mind. And, to be honest, I'm actually a bit hesitant to discuss AI at all because what I tell you today may already be out of date. That said, I think there are some foundational ways that you can use LLMs that will stand the test of time. 
:::


## Create Custom Instructions {.inverse}

:::{.big-number}
19
:::

::: {.notes}
My initial foray into using LLMs to work with code was, as I suspect was the case for many of you, through asking ChatGPT questions. And, like many of you, I found its answers at times incredibly helpful and at other times incredibly maddening. Sometimes it would give me base R code, other times tidyverse code. What I came to realize is that I needed to give it detailed instructions on what I wanted. And the best way to do this is to create custom instructions. Now, every time I ask an R question to an LLM, I do it with the following instructions:

> Please answer the following R question. When I program, I always like to use the tidyverse. Please don't ever give me base R solutions. Please also always use the native pipe (|>) not the tidyverse pipe (|>).

You can paste in instructions like this each time you work with your AI tool of choice. You can create custom GPTs in ChatGPT to save these custom instructions. I use a tool called Raycast for working with LLMs and it has a feature that allows me to create a custom AI prompt with these insturctions.

Every time I have a question for AI, I call up my AI chat preset, which has my instructions embedded in it, and get out answers tailored to my desired style of coding. 

**Resources**
- Simon Couch interview
:::

---

. . .

Please answer the following R question. 

. . .

When I program, I always like to use the tidyverse. 

. . .

Please don't ever give me base R solutions. 

. . .

Please also always use the native pipe (|>) not the tidyverse pipe (%>%).

## Use AI Directly in your Code Editor {.inverse}

:::{.big-number}
20
:::

::: {.notes}
Working with a tool like Raycast or ChatGPT requires you to go outside of your code editor. Another approach is to work with LLMs directly in your editor. If you use RStudio, you can connect directly with GitHub Copilot. If you use Positron, there are a number of extensions you can use to have LLMs interact directly with your code. Whether it's offering suggestions on improving your code, adding new code, or asking general questions about your code, these tools can be extremely helpful.
:::

### {.inverse}

<video
  data-autoplay
  loop
  src="assets/gh-copilot.mp4"
></video>

### {.inverse}

<video
  data-autoplay
  loop
  src="assets/windsurf.mp4"
></video>

## Show AI Your Data {.inverse}

:::{.big-number}
21
:::

::: {.notes}
A few months ago, I spoke with Posit developer Simon Couch, who is working on a range of R packages to interact with LLMs. Simon has written that:

> Data science differs a bit from software engineering here, though, in that the state of your R environment is just as important (or more so) than the contents of your files. 

In our conversation, Simon explained this further, saying that, when asking a question to an LLM, it's useful if it can see what the objects in your environment look like. The {gander} package solves this problem by passing information about your data frames alongside whatever request you make of an LLM.

**Resources**
- Podcast episode
- https://simonpcouch.github.io/gander/
:::

### {.inverse}

<video
  data-autoplay
  loop
  src="assets/gander.mp4"
></video>

# Use AI for Data Analysis  {.inverse background-image="assets/ai-analysis.jpg"}

::: {.notes}
LLMs are great for helping you write code to analyze your data. They can also do some of the data analysis for you. 

Now, before anything else, I have to say: please don't rely on LLMs for mission critical analysis without manually reviewing its work. Hallucinations are real.

With that said, the area I have found LLMs to be most helpful is with qualitative data. This data, which is often unstructured, is a perfect candidate for a tool that is comfortable bringing structure to messiness. Here are a few ways you can use it.
:::


## Translate Text {.inverse}

:::{.big-number}
22
:::

::: {.notes}
The {mall} package can also translate text. If you get responses in multiple languages, you can easily translate them to English. 
:::

---


```{r}
#| eval: false
#| echo: false

read_tsv("data/survey_spanish.tsv") |>
  filter(Qlike_best |> str_length() > 50) |>
  select(spanish = Qlike_best) |>
  view()
slice(2, 3, 10, 17, 34, 70, 67, 110, 133, 146) |>
  write_csv("data/survey_spanish.csv")
```


```{r}
library(tidyverse)

survey_spanish <-
  read_csv("data/survey_spanish.csv")
```

. . .

```{r}
#| echo: false

survey_spanish |>
  gt::gt() |>
  gt::opt_interactive()
```

---

```{r}
library(mall)

survey_translated <-
  survey_spanish |>
  llm_translate(spanish, language = "English", pred_name = "english")
```

. . .

```{r}
#| echo: false
survey_translated |>
  gt::gt() |>
  gt::opt_interactive(page_size_default = 5)
```

## Summarize Text {.inverse}

:::{.big-number}
23
:::

::: {.notes}
If you've ever conducted a survey or simply asked an open-ended question and got more text back than you could analyze by hand, why not try using AI for a quick and dirty analysis? The {mall} package lets you take long text and summarize it down to a shorter length.

**References**
- https://mlverse.github.io/mall/#summarize
:::

---

::: {.r-fit-text}
```{r}
survey_translated_summary <-
  survey_translated |>
  llm_summarize(english, max_words = 5, pred_name = "summary")
```
:::

---


```{r}
#| echo: false
survey_translated_summary |>
  gt::gt() |>
  gt::opt_interactive(page_size_default = 5)
```



## Create your Own Prompt to Analyze Text {.inverse}

:::{.big-number}
24
:::

::: {.notes}
The {mall} package provides some great out-of-the-box prompts you can use. You can also create your own prompts. I've used the {ellmer} package to interact directly with LLMs. 

Here, for example, I created my own function using {ellmer} to identify themes from a set of survey responses. 
:::

---

::: {.r-fit-text}
```{r}
library(ellmer)

identify_themes <- function(text) {
  chat <- chat_openai(
    system_prompt = "You are a sociologist,
    looking for the top three themes in the responses to a survey.
    Each response is separated by \n"
  )

  chat$chat(text)
}
```
:::

---

::: {.r-fit-text}
```{r}
survey_translated_combined <-
  survey_translated |>
  pull(english) |>
  paste(collapse = "\n")
```
:::

. . .

```{r}
#| echo: false
survey_translated_combined
```

---

::: {.r-fit-text}
```{r}
#| eval: false
survey_translated_combined |>
  identify_themes()
```
:::

---

```
Based on the survey responses provided, the top three themes appear to be:

1. **Open Source and Community Contributions**: Many responses highlight the benefits of R being open-source, emphasizing the cost-free access to robust 
data analysis tools and frequent updates driven by community contributions. The active community also offers a wealth of packages for various tasks, which
enhances the flexibility and capability of the software.

2. **Learning and Accessibility**: While there is mention of a steep learning curve initially, respondents note that learning R becomes easier over time. 
The diversity and availability of resources make it possible to quickly achieve results, encouraging continued learning and exploration.

3. **Functionality and Efficiency**: Respondents appreciate the range of statistical procedures that R can handle with ease, as well as the speed and 
efficiency in managing large datasets, such as through tools like rdata.table. The power of R's data structure, which aligns with mathematical concepts, 
and the wide variety of packages further contribute to its functionality.
```

::: {.notes}
https://www.garrickadenbuie.com/blog/llm-work-summary/
:::

# {.inverse}

::: {.notes}
I've now given you 24 things that you perhaps didn't know you could do with R. All of them are technical. But I'd be remiss if I didn't mention the one thing that you can do with R that is, in fact, the opposite of technical. 

When I started learning R, I never expected to find such a strong, welcoming community. But that's exactly what I've found. R has technical power, sure. But it also has the ability to bring a wide range of people together on a beautiful Saturday to sit all day in an air conditioned room.
:::

# Join the Community {.inverse}

:::{.big-number}
25
:::

::: {.notes}
You may not have ever considered it, but R can help you find your community. As you learn from others today, I hope that you will consider giving back to maintain and improve the wonderful R community that we all gain so much from. 

That I, a qualitative researcher who, for so long, thought of myself as not being a "real" user am up here today is in no small part because of the encouragement I have received from the R community. It may be a technical tool that brings us together in the first place, but it is the community that keeps us together in the long run. 
:::
